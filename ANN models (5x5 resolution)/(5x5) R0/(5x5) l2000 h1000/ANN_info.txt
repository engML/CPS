Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

>>> training using 1700 data for a batch size of 32 in progress...

Epoch: 0, loss:0.0001,  mean_absolute_error:0.0091,  val_loss:0.0002,  val_mean_absolute_error:0.0098,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0028,  val_loss:0.0001,  val_mean_absolute_error:0.0056,  
..................................................................
--- the loss for the training data is [5.2537241572281346e-05, 0.005089547485113144]

>>> training using 1700 data for a batch size of 64 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0012,  val_loss:0.0001,  val_mean_absolute_error:0.0050,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
.......................................................
--- the loss for the training data is [5.395601692725904e-05, 0.005110166966915131]

>>> training using 1700 data for a batch size of 128 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
.......................
--- the loss for the training data is [5.537572724279016e-05, 0.005191887263208628]

>>> training using 1700 data for a batch size of 256 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0006,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0005,  val_loss:0.0001,  val_mean_absolute_error:0.0052,  
.........
--- the loss for the training data is [5.522184073925018e-05, 0.005115503445267677]

>>> training using 1700 data for a batch size of 512 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0004,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0005,  val_loss:0.0001,  val_mean_absolute_error:0.0052,  
.....................................................
--- the loss for the training data is [5.5422620789613575e-05, 0.005134000908583403]

>>> training using 1700 data for a batch size of 1024 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0004,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0004,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
........
--- the loss for the training data is [5.537185643333942e-05, 0.005122264381498098]

>>> training using 1700 data for a batch size of 1700 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0002,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0002,  val_loss:0.0001,  val_mean_absolute_error:0.0051,  
.
--- the loss for the training data is [5.558060001931153e-05, 0.005135244224220514]
a batch size of 32 resulted in the best training loss of 5.2537241572281346e-05
Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

Test loss, accuracy: [4.641179839381948e-05, 0.00491551635786891]
--- Test0 relative error: mean = 2.25%, standard deviation = 2.50%

Validation loss, accuracy: [5.2537241572281346e-05, 0.005089547485113144]
--- Validation0 relative error: mean = 2.24%, standard deviation = 2.36%

Train loss, accuracy: [2.665128022272256e-06, 0.0012966423528268933]
--- Train0 relative error: mean = 0.55%, standard deviation = 0.49%

Simulation time: 31.48 seconds.
