Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

>>> training using 1700 data for a batch size of 32 in progress...

Epoch: 0, loss:0.0001,  mean_absolute_error:0.0058,  val_loss:0.0001,  val_mean_absolute_error:0.0061,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0015,  val_loss:0.0000,  val_mean_absolute_error:0.0029,  
..........
--- the loss for the training data is [1.658300061535556e-05, 0.00309867225587368]

>>> training using 1700 data for a batch size of 64 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0011,  val_loss:0.0000,  val_mean_absolute_error:0.0029,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0008,  val_loss:0.0000,  val_mean_absolute_error:0.0030,  
..........
--- the loss for the training data is [1.6584941477049142e-05, 0.0030386883299797773]

>>> training using 1700 data for a batch size of 128 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0008,  val_loss:0.0000,  val_mean_absolute_error:0.0029,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0008,  val_loss:0.0000,  val_mean_absolute_error:0.0030,  
.........................................................................................
--- the loss for the training data is [1.7875827325042337e-05, 0.0031439850572496653]

>>> training using 1700 data for a batch size of 256 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0030,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0006,  val_loss:0.0000,  val_mean_absolute_error:0.0030,  
................
--- the loss for the training data is [1.658932706050109e-05, 0.0030003071296960115]

>>> training using 1700 data for a batch size of 512 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0006,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0008,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
................
--- the loss for the training data is [1.7389882486895658e-05, 0.003112797625362873]

>>> training using 1700 data for a batch size of 1024 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0013,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0004,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
...................................................
--- the loss for the training data is [1.762832107488066e-05, 0.003085079602897167]

>>> training using 1700 data for a batch size of 1700 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0005,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0004,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
......
--- the loss for the training data is [1.7688149455352686e-05, 0.0031012101098895073]
a batch size of 32 resulted in the best training loss of 1.658300061535556e-05
Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

Test loss, accuracy: [1.270741722692037e-05, 0.002645180094987154]
--- Test0 relative error: mean = 0.30%, standard deviation = 0.27%

Validation loss, accuracy: [1.658300061535556e-05, 0.00309867225587368]
--- Validation0 relative error: mean = 0.36%, standard deviation = 0.30%

Train loss, accuracy: [2.07613516067795e-06, 0.0011332135181874037]
--- Train0 relative error: mean = 0.13%, standard deviation = 0.11%

Simulation time: 30.92 seconds.
