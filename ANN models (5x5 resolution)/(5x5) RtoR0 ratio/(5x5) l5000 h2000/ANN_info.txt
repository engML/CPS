Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

>>> training using 3400 data for a batch size of 32 in progress...

Epoch: 0, loss:0.0001,  mean_absolute_error:0.0056,  val_loss:0.0000,  val_mean_absolute_error:0.0035,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0019,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
.......................................................................
--- the loss for the training data is [1.9260303815826774e-05, 0.003179407212883234]

>>> training using 3400 data for a batch size of 64 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0014,  val_loss:0.0000,  val_mean_absolute_error:0.0033,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0012,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
..
--- the loss for the training data is [2.119936289091129e-05, 0.003298957133665681]

>>> training using 3400 data for a batch size of 128 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0013,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
.......
--- the loss for the training data is [1.9601468011387624e-05, 0.0031147985719144344]

>>> training using 3400 data for a batch size of 256 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
......................................
--- the loss for the training data is [1.9641087419586256e-05, 0.0031032999977469444]

>>> training using 3400 data for a batch size of 512 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0008,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
..................................................................
--- the loss for the training data is [1.9750425053643994e-05, 0.0031298426911234856]

>>> training using 3400 data for a batch size of 1024 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0010,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
..
--- the loss for the training data is [1.998287370952312e-05, 0.0031420006416738033]

>>> training using 3400 data for a batch size of 2048 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0031,  
...
--- the loss for the training data is [2.0077493900316767e-05, 0.0031864934135228395]

>>> training using 3400 data for a batch size of 3400 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0006,  val_loss:0.0000,  val_mean_absolute_error:0.0032,  
........................
--- the loss for the training data is [1.997529216168914e-05, 0.0031625309493392706]
a batch size of 32 resulted in the best training loss of 1.9260303815826774e-05
Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

Test loss, accuracy: [1.7776363165467046e-05, 0.003071667393669486]
--- Test0 relative error: mean = 0.35%, standard deviation = 0.32%

Validation loss, accuracy: [1.9260303815826774e-05, 0.003179407212883234]
--- Validation0 relative error: mean = 0.37%, standard deviation = 0.34%

Train loss, accuracy: [3.6924468531651655e-06, 0.0015446619363501668]
--- Train0 relative error: mean = 0.18%, standard deviation = 0.13%

Simulation time: 46.84 seconds.
