Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 125)               3250      
_________________________________________________________________
625_nodes_hidden_layer_2 (De (None, 625)               78750     
_________________________________________________________________
625_nodes_hidden_layer_3 (De (None, 625)               391250    
_________________________________________________________________
25_nodes_hidden_layer_4 (Den (None, 25)                15650     
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 488,926
Trainable params: 488,926
Non-trainable params: 0
_________________________________________________________________

>>> training using 4000 data for a batch size of 32 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0053,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0009,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0013,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0007,  
....................................................................................................
Epoch: 400, loss:0.0000,  mean_absolute_error:0.0011,  
.................................................................................................
--- the loss for the training data is [1.1194103990419535e-06, 0.0008672997355461121]

>>> training using 4000 data for a batch size of 64 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0005,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0003,  
................
--- the loss for the training data is [2.1473583444731048e-07, 0.00040252209873870015]

>>> training using 4000 data for a batch size of 128 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0002,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0002,  
...............................................
--- the loss for the training data is [7.528194601036375e-08, 0.00022898998577147722]

>>> training using 4000 data for a batch size of 256 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0003,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0004,  
.........................................................................
--- the loss for the training data is [9.143577450743123e-09, 7.105086842784658e-05]

>>> training using 4000 data for a batch size of 512 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0001,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0001,  
.....
--- the loss for the training data is [9.251263577425561e-08, 0.0002842792309820652]

>>> training using 4000 data for a batch size of 1024 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0002,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0004,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0000,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0000,  
....................................................................................................
Epoch: 400, loss:0.0000,  mean_absolute_error:0.0001,  
........................................
--- the loss for the training data is [2.7108148614729544e-08, 0.0001522432576166466]

>>> training using 4000 data for a batch size of 2048 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0001,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0007,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0000,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0003,  
...........................
--- the loss for the training data is [1.906993141176372e-08, 0.00013298852718435228]

>>> training using 4000 data for a batch size of 4000 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0001,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0000,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0001,  
...
--- the loss for the training data is [1.4146056548369756e-09, 1.606726618774701e-05]
a batch size of 4000 resulted in the best training loss of 1.4146056548369756e-09
Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 125)               3250      
_________________________________________________________________
625_nodes_hidden_layer_2 (De (None, 625)               78750     
_________________________________________________________________
625_nodes_hidden_layer_3 (De (None, 625)               391250    
_________________________________________________________________
25_nodes_hidden_layer_4 (Den (None, 25)                15650     
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 488,926
Trainable params: 488,926
Non-trainable params: 0
_________________________________________________________________

Test loss, accuracy: [1.0655869118636474e-05, 0.002333359094336629]
--- Test0 relative error: mean = 0.27%, standard deviation = 0.25%

Train loss, accuracy: [1.4146056548369756e-09, 1.606726618774701e-05]
--- Train0 relative error: mean = 0.00%, standard deviation = 0.00%

Simulation time: 544.90 seconds.
