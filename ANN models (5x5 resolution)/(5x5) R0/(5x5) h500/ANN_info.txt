Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

>>> training using 850 data for a batch size of 8 in progress...

Epoch: 0, loss:0.0421,  mean_absolute_error:0.1463,  val_loss:0.0114,  val_mean_absolute_error:0.0853,  
....................................................................................................
Epoch: 100, loss:0.0001,  mean_absolute_error:0.0073,  val_loss:0.0012,  val_mean_absolute_error:0.0270,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0039,  val_loss:0.0006,  val_mean_absolute_error:0.0195,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0037,  val_loss:0.0004,  val_mean_absolute_error:0.0154,  
....................................................................................................
Epoch: 400, loss:0.0000,  mean_absolute_error:0.0019,  val_loss:0.0004,  val_mean_absolute_error:0.0141,  
....................................................................................................
Epoch: 500, loss:0.0000,  mean_absolute_error:0.0031,  val_loss:0.0004,  val_mean_absolute_error:0.0132,  
....................................................................................................
Epoch: 600, loss:0.0000,  mean_absolute_error:0.0026,  val_loss:0.0003,  val_mean_absolute_error:0.0122,  
....................................................................................................
Epoch: 700, loss:0.0000,  mean_absolute_error:0.0025,  val_loss:0.0003,  val_mean_absolute_error:0.0117,  
....................................................................................................
Epoch: 800, loss:0.0000,  mean_absolute_error:0.0026,  val_loss:0.0003,  val_mean_absolute_error:0.0115,  
...............................................................................................
--- the loss for the training data is [0.0002596698759589344, 0.0110999196767807]

>>> training using 850 data for a batch size of 16 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0013,  val_loss:0.0003,  val_mean_absolute_error:0.0110,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0017,  val_loss:0.0003,  val_mean_absolute_error:0.0112,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0012,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
.............
--- the loss for the training data is [0.00023650191724300385, 0.010777276009321213]

>>> training using 850 data for a batch size of 32 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0002,  val_mean_absolute_error:0.0107,  
....................................................................................................
Epoch: 200, loss:0.0000,  mean_absolute_error:0.0025,  val_loss:0.0002,  val_mean_absolute_error:0.0109,  
....................................................................................................
Epoch: 300, loss:0.0000,  mean_absolute_error:0.0003,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
.......................................
--- the loss for the training data is [0.0002448229060973972, 0.01091470755636692]

>>> training using 850 data for a batch size of 64 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0009,  val_loss:0.0002,  val_mean_absolute_error:0.0107,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0005,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
..................................................................................................
--- the loss for the training data is [0.00023880777007434517, 0.010553731583058834]

>>> training using 850 data for a batch size of 128 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0007,  val_loss:0.0002,  val_mean_absolute_error:0.0107,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0000,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
..................
--- the loss for the training data is [0.00023528684687335044, 0.010602883994579315]

>>> training using 850 data for a batch size of 256 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0000,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0002,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
.....................................................................................
--- the loss for the training data is [0.00023503944976255298, 0.010602710768580437]

>>> training using 850 data for a batch size of 512 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0003,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0001,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
.....................................................................
--- the loss for the training data is [0.000235231316764839, 0.010599330998957157]

>>> training using 850 data for a batch size of 850 in progress...

Epoch: 0, loss:0.0000,  mean_absolute_error:0.0000,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
....................................................................................................
Epoch: 100, loss:0.0000,  mean_absolute_error:0.0000,  val_loss:0.0002,  val_mean_absolute_error:0.0106,  
........................
--- the loss for the training data is [0.00023518636589869857, 0.010599241591989994]
a batch size of 256 resulted in the best training loss of 0.00023503944976255298
Model: "FFNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 25)]              0         
_________________________________________________________________
125_nodes_hidden_layer_1 (De (None, 50)                1300      
_________________________________________________________________
50_nodes_hidden_layer_2 (Den (None, 50)                2550      
_________________________________________________________________
25_nodes_hidden_layer_3 (Den (None, 25)                1275      
_________________________________________________________________
output_R_eff (Dense)         (None, 1)                 26        
=================================================================
Total params: 5,151
Trainable params: 5,151
Non-trainable params: 0
_________________________________________________________________

Test loss, accuracy: [0.0002005568239837885, 0.009819203056395054]
--- Test0 relative error: mean = 4.33%, standard deviation = 4.69%

Validation loss, accuracy: [0.00023503944976255298, 0.010602710768580437]
--- Validation0 relative error: mean = 4.61%, standard deviation = 5.02%

Train loss, accuracy: [8.888473246315698e-08, 0.00024977364228107035]
--- Train0 relative error: mean = 0.11%, standard deviation = 0.08%

Simulation time: 122.08 seconds.
